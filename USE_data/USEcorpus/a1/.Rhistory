typeof(USE1_negative_int)
USE1_negative_int
USE1_negative_int <- as.integer(as.character(as.single(USE1_negative)))
USE2_negative_int <- as.integer(as.character(as.single(USE2_negative)))
cohensD( x = USE1_negative_int, y = USE2_negative_int, data = ttest_negative, method = "pooled", mu = 0, formula = NULL )
install.packages("devtools")
devtools::install_github("easystats/effectsize")
install.packages("devtools")
devtools::install_github("easystats/effectsize")
# Run some stats for comparison
ttest_positive <- t.test(USE1_positive, USE2_positive, alternative = c("two.sided"))
ttest_negative <- t.test(USE1_negative, USE2_negative, alternative = c("two.sided"))
ttest_negative
featureV <- c("i", "we", "us", "you") # Update this to be more interesting topics
querydfm2 <- dfm_match(dfm(mydfm2), featureV)
querydfm2
querydfm <- dfm_match(dfm(mydfm1), featureV)
querydfm
t.test(querydfm, querydfm2)
featureV <- c("i", "we") # Update this to be more interesting topics
querydfm <- dfm_match(dfm(mydfm1), featureV)
querydfm2 <- dfm_match(dfm(mydfm2), featureV)
t.test(querydfm, querydfm2)
featureV <- c("us") # Update this to be more interesting topics
querydfm <- dfm_match(dfm(mydfm1), featureV)
querydfm
querydfm2 <- dfm_match(dfm(mydfm2), featureV)
querydfm2
t.test(querydfm, querydfm2)
featureV <- c("we") # Update this to be more interesting topics
querydfm <- dfm_match(dfm(mydfm1), featureV)
querydfm
e
e
querydfm2 <- dfm_match(dfm(mydfm2), featureV)
querydfm2
t.test(querydfm, querydfm2)
featureV <- c("i") # Update this to be more interesting topics
querydfm <- dfm_match(dfm(mydfm1), featureV)
querydfm
querydfm2 <- dfm_match(dfm(mydfm2), featureV)
querydfm2
t.test(querydfm, querydfm2)
featureV <- c("us") # Update this to be more interesting topics
querydfm
querydfm <- dfm_match(dfm(mydfm1), featureV)
querydfm
querydfm2 <- dfm_match(dfm(mydfm2), featureV)
querydfm2
t.test(querydfm, querydfm2)
featureV <- c("we") # Update this to be more interesting topics
querydfm <- dfm_match(dfm(mydfm1), featureV)
querydfm
querydfm2 <- dfm_match(dfm(mydfm2), featureV)
querydfm2
t.test(querydfm, querydfm2) # us significant;
featureV <- c("we") # Update this to be more interesting topics
querydfm <- dfm_match(dfm(mydfm1), featureV)
querydfm
querydfm2 <- dfm_match(dfm(mydfm2), featureV)
querydfm2
t.test(querydfm, querydfm2) # us significant;
featureV <- c("us") # Update this to be more interesting topics
querydfm <- dfm_match(dfm(mydfm1), featureV)
querydfm
querydfm2 <- dfm_match(dfm(mydfm2), featureV)
querydfm2
t.test(querydfm, querydfm2) # us significant;
featureV <- c("i", "you", "we", "us") # Update this to be more interesting topics
querydfm <- dfm_match(dfm(mydfm1), featureV)
querydfm
querydfm2 <- dfm_match(dfm(mydfm2), featureV)
querydfm2
t.test(querydfm, querydfm2) # us significant;
featureV <- c("you") # Update this to be more interesting topics
querydfm <- dfm_match(dfm(mydfm1), featureV)
querydfm
querydfm2 <- dfm_match(dfm(mydfm2), featureV)
querydfm2
t.test(querydfm, querydfm2) # us significant;
featureV <- c("us") # Update this to be more interesting topics
querydfm <- dfm_match(dfm(mydfm1), featureV)
querydfm
querydfm2 <- dfm_match(dfm(mydfm2), featureV)
querydfm2
t.test(querydfm, querydfm2) # us significant;
sentsAFINN = get_sentiments("afinn")
afinn_negative1 <- USE1_negative %>%
inner_join(get_sentiments("afinn")) %>%
group_by(index = linenumber %/% 80) %>%
summarise(sentiment = sum(value)) %>%
mutate(method = "AFINN")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
library(dplyr)
afinn_negative1 <- USE1_negative %>%
inner_join(get_sentiments("afinn")) %>%
group_by(index = linenumber %/% 80) %>%
summarise(sentiment = sum(value)) %>%
mutate(method = "AFINN")
afinn_negative1 <- USE_nostop %>%
inner_join(get_sentiments("afinn")) %>%
group_by(index = linenumber %/% 80) %>%
summarise(sentiment = sum(value)) %>%
mutate(method = "AFINN")
sentsAFINN
positive
summary(sentsAFINN)
sentsAFINN.Min
sentsAFINN$value
install.packages("tidyverse")
library(tidyverse)
# USE a1 - My English prompt
for (i in 1:iterations2) {
USE2_nostop <- gsub(",","", toString(USE2_dataMerge[i]))
USE2_nostop = tolower(unlist(strsplit(USE2_nostop," ")))
m_positive = mean(USE2_nostop %in% positive)
USE2_positive = rbind(m_positive, USE2_positive)
USE2_positive
m_negative = mean(USE2_nostop %in% negative)
USE2_negative = rbind(m_negative, USE2_negative)
USE2_negative
USE2_afinn <- USE2_nostop %>%
inner_join(get_sentiments("afinn"))
}
USE2_nostop
m_negative
USE2_afinn <- USE2_nostop %>%
inner_join(get_sentiments("bing"))
USE_nostop %in% positive
sents_afinn = get_sentiments("afinn")
sents = get_sentiments("nrc")
library(tidytext)
library(quanteda) # Info on using quanteda: https://quanteda.io/articles/pkgdown/examples/lsa.html
library("quanteda.textmodels")
library(rvest) # For wrangling the .txt files and the html within them
library(ggplot2)
sentsAFINN = get_sentiments("afinn")
sentsAFINN
USE_nostop
USE1_bing <- USE_nostop %>%
inner_join(get_sentiments("bing")) %>%
count(book, index = linenumber %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
USE1_bing <- USE_nostop %>%
inner_join(get_sentiments("bing")) %>%
count(book, index = linenumber %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
inner_join(get_sentiments("bing")) %>%
inner_join(get_sentiments("bing"))
?count
USE1_bing <- USE_nostop %>%
inner_join(get_sentiments("bing")) %>%
count(USE_nostop, index = linenumber %/% 80, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
# Run some stats for comparison
ttest_positive <- t.test(USE1_positive, USE2_positive, alternative = c("two.sided"))
ttest_negative <- t.test(USE1_negative, USE2_negative, alternative = c("two.sided"))
ttest_positive
ttest_negative
# Literature prompt
topfeatures(mydfm1, 20)
# My English prompt
topfeatures(mydfm2, 20)
t.test(querydfm, querydfm2) # us significant
tstat_freq1 <- textstat_frequency(ngram_dfm1, n = 20)
head(tstat_freq1, 20)
tstat_freq2 <- textstat_frequency(ngram_dfm2, n = 20)
head(tstat_freq2, 20)
USE_lsa
?count
mydfm1
USE2_nostop
length(USE2_nostop)
length(USE_nostop)
# USE a4 - Literature prompt
for (i in 1:iterations) {
USE_nostop <- gsub(",","", toString(USE_dataMerge[i]))
USE_nostop = tolower(unlist(strsplit(USE_nostop," ")))
USE1_length = rbind(USE_nostop)
m_positive = mean(USE_nostop %in% positive)
USE1_positive = rbind(m_positive, USE1_positive)
USE1_positive
m_negative = mean(USE_nostop %in% negative)
USE1_negative = rbind(m_negative, USE1_negative)
USE1_negative
}
USE1_length
length(USE1_length)
USE1_length = NULL
# USE a4 - Literature prompt
for (i in 1:iterations) {
USE_nostop <- gsub(",","", toString(USE_dataMerge[i]))
USE_nostop = tolower(unlist(strsplit(USE_nostop," ")))
USE1_length = rbind(length(USE_nostop))
m_positive = mean(USE_nostop %in% positive)
USE1_positive = rbind(m_positive, USE1_positive)
USE1_positive
m_negative = mean(USE_nostop %in% negative)
USE1_negative = rbind(m_negative, USE1_negative)
USE1_negative
}
USE1_length
# USE a4 - Literature prompt
for (i in 1:iterations) {
USE_nostop <- gsub(",","", toString(USE_dataMerge[i]))
USE_nostop = tolower(unlist(strsplit(USE_nostop," ")))
print(length(USE_nostop))
m_positive = mean(USE_nostop %in% positive)
USE1_positive = rbind(m_positive, USE1_positive)
USE1_positive
m_negative = mean(USE_nostop %in% negative)
USE1_negative = rbind(m_negative, USE1_negative)
USE1_negative
}
USE1_length <- c()
# USE a4 - Literature prompt
for (i in 1:iterations) {
USE_nostop <- gsub(",","", toString(USE_dataMerge[i]))
USE_nostop = tolower(unlist(strsplit(USE_nostop," ")))
USE1_length <- c(length(USE_nostop))
m_positive = mean(USE_nostop %in% positive)
USE1_positive = rbind(m_positive, USE1_positive)
USE1_positive
m_negative = mean(USE_nostop %in% negative)
USE1_negative = rbind(m_negative, USE1_negative)
USE1_negative
}
USE1_length
?c
USE1_length <- c()
# USE a4 - Literature prompt
for (i in 1:iterations) {
USE_nostop <- gsub(",","", toString(USE_dataMerge[i]))
USE_nostop = tolower(unlist(strsplit(USE_nostop," ")))
USE1_length <- c(USE1_length, length(USE_nostop))
m_positive = mean(USE_nostop %in% positive)
USE1_positive = rbind(m_positive, USE1_positive)
USE1_positive
m_negative = mean(USE_nostop %in% negative)
USE1_negative = rbind(m_negative, USE1_negative)
USE1_negative
}
USE1_length
mean(USE1_length)
USE2_length <- c()
# USE a1 - My English prompt
for (i in 1:iterations2) {
USE2_nostop <- gsub(",","", toString(USE2_dataMerge[i]))
USE2_nostop = tolower(unlist(strsplit(USE2_nostop," ")))
USE2_length <- c(USE2_length, length(USE2_nostop))
m_positive = mean(USE2_nostop %in% positive)
USE2_positive = rbind(m_positive, USE2_positive)
USE2_positive
m_negative = mean(USE2_nostop %in% negative)
USE2_negative = rbind(m_negative, USE2_negative)
USE2_negative
USE2_afinn <- USE2_nostop %>%
inner_join(get_sentiments("bing"))
}
# USE a1 - My English prompt
for (i in 1:iterations2) {
USE2_nostop <- gsub(",","", toString(USE2_dataMerge[i]))
USE2_nostop = tolower(unlist(strsplit(USE2_nostop," ")))
USE2_length <- c(USE2_length, length(USE2_nostop))
m_positive = mean(USE2_nostop %in% positive)
USE2_positive = rbind(m_positive, USE2_positive)
USE2_positive
m_negative = mean(USE2_nostop %in% negative)
USE2_negative = rbind(m_negative, USE2_negative)
USE2_negative
}
# Compare word counts
t.test(USE1_length, USE2_length)
var(USE1_length)
var(USE2_length)
# Compare word counts
ttest_count <- t.test(USE1_length, USE2_length)
ttest_count
# Literature prompt
textplot_wordcloud(mydfm1, colors = RColorBrewer::brewer.pal(8,  "Dark2"), scale = c(4,0.1))
# My English prompt
textplot_wordcloud(mydfm2, colors = RColorBrewer::brewer.pal(8,  "Dark2"), scale = c(8,0.1))
# My English prompt
textplot_wordcloud(mydfm2, colors = RColorBrewer::brewer.pal(8,  "Dark2"), scale = c(10,0.1))
# My English prompt
textplot_wordcloud(mydfm2, colors = RColorBrewer::brewer.pal(8,  "Dark2"), scale = c(4,0.1))
?textplot_wordcloud
# My English prompt
textplot_wordcloud(mydfm2, colors = RColorBrewer::brewer.pal(8,  "Dark2"))
# Literature prompt
textplot_wordcloud(mydfm1, colors = RColorBrewer::brewer.pal(8,  "Dark2"))
head(tstat_freq1, 20)
featureV <- c("*�*") # Update this to be more interesting topics
querydfm <- dfm_match(dfm(mydfm1), featureV)
querydfm
querydfm2 <- dfm_match(dfm(mydfm2), featureV)
querydfm2
t.test(querydfm, querydfm2) # us is significant
querydfm
head(tstat_freq1, 20)
head(tstat_freq2, 20)
# Literature prompt
textplot_wordcloud(mydfm1, colors = RColorBrewer::brewer.pal(8,  "Dark2"))
# My English prompt
textplot_wordcloud(mydfm2, colors = RColorBrewer::brewer.pal(8,  "Dark2"))
head(tstat_freq1, 20)
# Compare word counts
ttest_count <- t.test(USE1_length, USE2_length)
ttest_count
USE2_length
hist(USE2_length)
# Compare word counts
hist(USE1_length)
hist(USE2_length)
USE2_positive
hist(USE2_positive)
hist(USE1_positive)
hist(USE1_negative)
hist(USE2_negative)
debugger <- dfm(USE2_dataMerge, select = "*�*")  # Tracking down mystery ? symbol to see what the cause is
debugger
featureV <- c("us") # Update this to be more interesting topics
# Literature prompt
topfeatures(mydfm1, 20)
# My English prompt
topfeatures(mydfm2, 20)
featureV <- c("time") # Update this to be more interesting topics
querydfm <- dfm_match(dfm(mydfm1), featureV)
querydfm
querydfm2 <- dfm_match(dfm(mydfm2), featureV)
querydfm2
t.test(querydfm, querydfm2) # us is significant
querydfm2
mean(querydfm2)
querydfm2$time
querydfm2[,1]
querydfm2[1,]
querydfm2[,1]
querydfm2[,2]
querydfm2[,1]
querydfm2
t.test(querydfm, querydfm2) # us is significant
featureV <- c("like") # Update this to be more interesting topics
querydfm <- dfm_match(dfm(mydfm1), featureV)
querydfm
querydfm2 <- dfm_match(dfm(mydfm2), featureV)
querydfm2
t.test(querydfm, querydfm2) # us is significant
?dfm_match
querydfm2@docvars
querydfm2@meta
querydfm2@i
querydfm2@p
querydfm2@Dim
querydfm2@Dimnames
querydfm2@x
querydfm2
mean(querydfm2@x)
mean(querydfm@x)
t.test(querydfm, querydfm2) # us is significant
featureV <- c("can") # Update this to be more interesting topics
querydfm <- dfm_match(dfm(mydfm1), featureV)
querydfm
querydfm2 <- dfm_match(dfm(mydfm2), featureV)
querydfm2
t.test(querydfm, querydfm2) # us is significant
featureV <- c("also") # Update this to be more interesting topics
querydfm <- dfm_match(dfm(mydfm1), featureV)
querydfm
querydfm2 <- dfm_match(dfm(mydfm2), featureV)
querydfm2
t.test(querydfm, querydfm2) # us is significant
featureV <- c("time") # Update this to be more interesting topics
querydfm <- dfm_match(dfm(mydfm1), featureV)
querydfm
querydfm2 <- dfm_match(dfm(mydfm2), featureV)
querydfm2
t.test(querydfm, querydfm2) # us is significant
?teststat_dist
?teststat
?quanteda
textstat_dist(
x = mydfm1,
y = mydfm2,
selection = NULL,
margin = c("documents", "features"),
method = c("euclidean", "manhattan", "maximum", "canberra", "minkowski"),
p = 2,
...
)
textstat_dist(
x = mydfm1,
y = mydfm2,
selection = NULL,
margin = c("documents", "features"),
method = c("euclidean", "manhattan", "maximum", "canberra", "minkowski"),
p = 2
)
textstat_dist(
x = mydfm1,
y = mydfm2,
selection = NULL,
margin = c("documents"),
p = 2
)
tstat_similarity <- textstat_dist(
x = mydfm1,
y = mydfm2,
selection = NULL,
margin = c("documents"),
p = 2
)
as.list(tstat_similarity)
# Literature prompt
frequency_plot1 <- textstat_frequency(mydfm1, n= 1000) %>%
ggplot(aes(x= rank, y = frequency)) + geom_point() + labs(x= "Frequency Rank", y = "Frequency Term") + ggtitle("Word Frequency vs. Rank")
frequency_plot1
# My English prompt
frequency_plot2 <- textstat_frequency(mydfm2, n= 1000) %>%
ggplot(aes(x= rank, y = frequency)) + geom_point() + labs(x= "Frequency Rank", y = "Frequency Term") + ggtitle("Word Frequency vs. Rank")
frequency_plot2
frequency_plot1
# My English prompt
frequency_plot2 <- textstat_frequency(mydfm2, n= 1000) %>%
ggplot(aes(x= rank, y = frequency)) + geom_point() + labs(x= "Frequency Rank", y = "Frequency Term") + ggtitle("Word Frequency vs. Rank")
frequency_plot2
mydfm2
mylsa2
# Literature prompt
textplot_wordcloud(mydfm1, colors = RColorBrewer::brewer.pal(8,  "Dark2"))
# My English prompt
textplot_wordcloud(mydfm2, colors = RColorBrewer::brewer.pal(8,  "Dark2"))
# Literature prompt
textplot_wordcloud(mydfm1, max_words = 100, colors = RColorBrewer::brewer.pal(8,  "Dark2"))
# Literature prompt
textplot_wordcloud(mydfm1, max_words = 500, colors = RColorBrewer::brewer.pal(8,  "Dark2"))
# My English prompt
textplot_wordcloud(mydfm2, max_words = 500, colors = RColorBrewer::brewer.pal(8,  "Dark2"))
# Literature prompt
textplot_wordcloud(mydfm1, max_words = 500, colors = RColorBrewer::brewer.pal(8,  "Dark2"))
# Literature prompt
textplot_wordcloud(mydfm1, max_words = 500, colors = RColorBrewer::brewer.pal(8,  "Dark2"), comparison = TRUE)
# Literature prompt
textplot_wordcloud(mydfm1, max_words = 500, colors = RColorBrewer::brewer.pal(8,  "Dark2"))
# Get top features
topfeatures(mydfm1, 20) # Lit prompt
topfeatures(mydfm2, 20) # My English prompt
4410/1304
786/779
# My English prompt
textplot_wordcloud(mydfm2, max_words = 500, colors = RColorBrewer::brewer.pal(8,  "Dark2"))
tstat_similarity <- textstat_dist(
x = mydfm1,
y = mydfm2,
selection = NULL,
margin = c("documents"),
p = 2
)
tstat_similarity
# Compare words that appear in top features for both prompts - like, can, time, also
t.test(querydfm, querydfm2) # us is significant
featureV <- c("time") # Tried individual terms for the sake of running t-test -> the terms I looked at were words in common across each essay group's 20 top features - like, can, time, and also. Time was the only one that was significantly different and as such is kept here.
# Literature prompt
querydfm <- dfm_match(dfm(mydfm1), featureV)
querydfm
# My English prompt
querydfm2 <- dfm_match(dfm(mydfm2), featureV)
querydfm2
# Compare words that appear in top features for both prompts - like, can, time, also
t.test(querydfm, querydfm2) # us is significant
featureV <- c("like") # Tried individual terms for the sake of running t-test -> the terms I looked at were words in common across each essay group's 20 top features - like, can, time, and also. Like was the only one that was significantly different and as such is kept here.
# Literature prompt
querydfm <- dfm_match(dfm(mydfm1), featureV)
querydfm
# My English prompt
querydfm2 <- dfm_match(dfm(mydfm2), featureV)
querydfm2
# Compare words that appear in top features for both prompts - like, can, time, also
t.test(querydfm, querydfm2) # us is significant
# Literature prompt
frequency_plot1 <- textstat_frequency(mydfm1, n= 1000) %>%
ggplot(aes(x= rank, y = frequency)) + geom_point() + labs(x= "Frequency Rank", y = "Frequency Term") + ggtitle("Word Frequency vs. Rank")
frequency_plot1
# Literature prompt
frequency_plot1 <- textstat_frequency(mydfm1, n= 1000) %>%
ggplot(aes(x= rank, y = frequency)) + geom_point() + labs(x= "Frequency Rank", y = "Frequency Term") + ggtitle("Word frequency for Literature prompt")
# My English prompt
frequency_plot2 <- textstat_frequency(mydfm2, n= 1000) %>%
ggplot(aes(x= rank, y = frequency)) + geom_point() + labs(x= "Frequency Rank", y = "Frequency Term") + ggtitle("Word frequency for \"My English\" prompt")
frequency_plot1
frequency_plot2
querydfm
# Compare words that appear in top features for both prompts - like, can, time, also
t.test(querydfm, querydfm2) # us is significant
# Get top features
topfeatures(mydfm1, 20) # Lit prompt
topfeatures(mydfm2, 20) # My English prompt
